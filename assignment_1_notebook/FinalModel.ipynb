{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to load data\n",
    "def load_data(filepath):\n",
    "    # setting column names of the dataframe\n",
    "    headers = [\n",
    "        \"X_robot\",\n",
    "        \"Y_robot\",\n",
    "        \"Orientation_robot\",\n",
    "        \"Collision\",\n",
    "        \"X_candle1\",\n",
    "        \"Y_candle1\",\n",
    "        \"X_candle2\",\n",
    "        \"Y_candle2\",\n",
    "        \"X_candle3\",\n",
    "        \"Y_candle3\",\n",
    "        \"X_candle4\",\n",
    "        \"Y_candle4\",\n",
    "        \"X_speed\",\n",
    "        \"Y_speed\",\n",
    "    ]\n",
    "\n",
    "    # load data from file\n",
    "    df = pd.read_csv(filepath, names=headers)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate Euclidean distance between two points\n",
    "def euclidean_distance(x1, y1, x2, y2):\n",
    "    return ((x1 - x2) ** 2 + (y1 - y2) ** 2) ** 0.5\n",
    "\n",
    "\n",
    "# function that performs feature engineering on the dataset\n",
    "def feature_engineering(robots_df):\n",
    "    # calculating the distance between the robot and each candle\n",
    "    robots_df[\"distance_candle1\"] = euclidean_distance(\n",
    "        robots_df[\"X_robot\"],\n",
    "        robots_df[\"Y_robot\"],\n",
    "        robots_df[\"X_candle1\"],\n",
    "        robots_df[\"Y_candle1\"],\n",
    "    )\n",
    "    robots_df[\"distance_candle2\"] = euclidean_distance(\n",
    "        robots_df[\"X_robot\"],\n",
    "        robots_df[\"Y_robot\"],\n",
    "        robots_df[\"X_candle2\"],\n",
    "        robots_df[\"Y_candle2\"],\n",
    "    )\n",
    "    robots_df[\"distance_candle3\"] = euclidean_distance(\n",
    "        robots_df[\"X_robot\"],\n",
    "        robots_df[\"Y_robot\"],\n",
    "        robots_df[\"X_candle3\"],\n",
    "        robots_df[\"Y_candle3\"],\n",
    "    )\n",
    "    robots_df[\"distance_candle4\"] = euclidean_distance(\n",
    "        robots_df[\"X_robot\"],\n",
    "        robots_df[\"Y_robot\"],\n",
    "        robots_df[\"X_candle4\"],\n",
    "        robots_df[\"Y_candle4\"],\n",
    "    )\n",
    "\n",
    "    # calculating the distance between the robot and each candle in each axis\n",
    "    robots_df[\"distance_candle1_x\"] = robots_df[\"X_robot\"] - robots_df[\"X_candle1\"]\n",
    "    robots_df[\"distance_candle1_y\"] = robots_df[\"Y_robot\"] - robots_df[\"Y_candle1\"]\n",
    "    robots_df[\"distance_candle2_x\"] = robots_df[\"X_robot\"] - robots_df[\"X_candle2\"]\n",
    "    robots_df[\"distance_candle2_y\"] = robots_df[\"Y_robot\"] - robots_df[\"Y_candle2\"]\n",
    "    robots_df[\"distance_candle3_x\"] = robots_df[\"X_robot\"] - robots_df[\"X_candle3\"]\n",
    "    robots_df[\"distance_candle3_y\"] = robots_df[\"Y_robot\"] - robots_df[\"Y_candle3\"]\n",
    "    robots_df[\"distance_candle4_x\"] = robots_df[\"X_robot\"] - robots_df[\"X_candle4\"]\n",
    "    robots_df[\"distance_candle4_y\"] = robots_df[\"Y_robot\"] - robots_df[\"Y_candle4\"]\n",
    "\n",
    "    return robots_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to develop and save the model\n",
    "def develop(X, y):\n",
    "    # split the data into training, validation and test sets\n",
    "    X_train_validate, X_test, y_train_validate, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    X_train, X_validate, y_train, y_validate = train_test_split(\n",
    "        X_train_validate, y_train_validate, test_size=0.125, random_state=42\n",
    "    )\n",
    "\n",
    "    # scale the data\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_validate_scaled = scaler.transform(X_validate)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "    X_validate_scaled = pd.DataFrame(X_validate_scaled, columns=X_validate.columns)\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "    # apply PCA to reduce the dimensionality of the data\n",
    "    pca = PCA(n_components=0.95).fit(X_train_scaled)\n",
    "    x_train_pca = pca.transform(X_train_scaled)\n",
    "    x_validate_pca = pca.transform(X_validate_scaled)\n",
    "    x_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "    # train the model\n",
    "    hyper_params = {\n",
    "        # \"hidden_layer_sizes\": (100, 100),\n",
    "        # \"activation\": \"relu\",\n",
    "        # \"solver\": \"adam\",\n",
    "        # \"max_iter\": 1000,\n",
    "        # \"random_state\": 33,\n",
    "        # \"batch_size\": 32,\n",
    "        # \"learning_rate_init\": \"0.001\",\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "    model = MLPRegressor(**hyper_params).fit(x_train_pca, y_train)\n",
    "\n",
    "    # evaluate the model\n",
    "    train_score = model.score(x_train_pca, y_train)\n",
    "    validate_score = model.score(x_validate_pca, y_validate)\n",
    "    test_score = model.score(x_test_pca, y_test)\n",
    "\n",
    "    # model props\n",
    "    model_props = {\n",
    "        \"id\": id,\n",
    "        \"hidden_layers\": model.n_layers_ - 2,\n",
    "        \"architecture\": model.hidden_layer_sizes,\n",
    "        \"activation\": model.activation,\n",
    "        \"batch_size\": model.batch_size,\n",
    "        \"solver\": model.solver,\n",
    "        \"learning_rate_init\": model.learning_rate_init,\n",
    "        \"learning_rate\": model.learning_rate,\n",
    "        \"iterations\": model.n_iter_,\n",
    "        \"train_score\": train_score,\n",
    "        \"val_score\": validate_score,\n",
    "        \"test_score\": test_score,\n",
    "    }\n",
    "\n",
    "    # print the model properties\n",
    "    print(model_props)\n",
    "\n",
    "    # save the scaler\n",
    "    with open(\"scaler.pkl\", \"wb\") as f:\n",
    "        pickle.dump(scaler, f)\n",
    "\n",
    "    # save the pca\n",
    "    with open(\"pca.pkl\", \"wb\") as f:\n",
    "        pickle.dump(pca, f)\n",
    "\n",
    "    # save the model\n",
    "    with open(\"model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to evaluate the model\n",
    "def evaluate(X, y):\n",
    "    scaler = pickle.load(open(\"scaler.pkl\", \"rb\"))\n",
    "    model = pickle.load(open(\"model.pkl\", \"rb\"))\n",
    "    pca = pickle.load(open(\"pca.pkl\", \"rb\"))\n",
    "\n",
    "    # scale the data\n",
    "    X_scaled = scaler.transform(X)\n",
    "    X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "    # apply PCA to reduce the dimensionality of the data\n",
    "    x_pca = pca.transform(X_scaled)\n",
    "\n",
    "    # evaluate the model\n",
    "    test_score = model.score(x_pca, y)\n",
    "\n",
    "    # model props\n",
    "    model_props = {\n",
    "        \"id\": id,\n",
    "        \"hidden_layers\": model.n_layers_ - 2,\n",
    "        \"architecture\": model.hidden_layer_sizes,\n",
    "        \"activation\": model.activation,\n",
    "        \"batch_size\": model.batch_size,\n",
    "        \"solver\": model.solver,\n",
    "        \"learning_rate_init\": model.learning_rate_init,\n",
    "        \"learning_rate\": model.learning_rate,\n",
    "        \"iterations\": model.n_iter_,\n",
    "        \"test_score\": test_score,\n",
    "    }\n",
    "\n",
    "    # print the model properties\n",
    "    print(model_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the main function that runs the program\n",
    "def main(mode=\"develop\", file_path=\"./data/RobotData.csv\"):\n",
    "\n",
    "    # Load data\n",
    "    df = load_data(file_path)\n",
    "\n",
    "    # data augmentation needs to be done here, if required\n",
    "\n",
    "    # Perform feature engineering\n",
    "    df_fe = feature_engineering(df)\n",
    "\n",
    "    # print head of the dataframe\n",
    "    # print(df_fe.head())\n",
    "\n",
    "    # selected features\n",
    "    selected_features = [\n",
    "        \"distance_candle1\",\n",
    "        \"distance_candle2\",\n",
    "        \"distance_candle3\",\n",
    "        \"distance_candle4\",\n",
    "        \"distance_candle1_x\",\n",
    "        \"distance_candle1_y\",\n",
    "        \"distance_candle2_x\",\n",
    "        \"distance_candle2_y\",\n",
    "        \"distance_candle3_x\",\n",
    "        \"distance_candle3_y\",\n",
    "        \"distance_candle4_x\",\n",
    "        \"distance_candle4_y\",\n",
    "    ]\n",
    "\n",
    "    # target variables\n",
    "    target = [\"X_speed\", \"Y_speed\"]\n",
    "\n",
    "    # get feature and target vectors\n",
    "    X = df_fe[selected_features]\n",
    "    y = df_fe[target]\n",
    "\n",
    "    # scale the data\n",
    "    if mode == \"develop\":\n",
    "        develop(X, y)\n",
    "    else:\n",
    "        evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': <built-in function id>, 'hidden_layers': 1, 'architecture': (100,), 'activation': 'relu', 'batch_size': 'auto', 'solver': 'adam', 'learning_rate_init': 0.001, 'learning_rate': 'constant', 'iterations': 17, 'train_score': 0.09927035729657985, 'val_score': 0.05454017370733505, 'test_score': 0.04584405168090577}\n"
     ]
    }
   ],
   "source": [
    "# run the main function\n",
    "main(\"develop\", \"./data/RobotData.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
